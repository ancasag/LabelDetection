{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R86up5pWLR3d"
   },
   "source": [
    "# Creating a Mask RCNN model\n",
    "\n",
    "We first install the Mask RCNN library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4MPAM7JwKF3w"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/matterport/Mask_RCNN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFBrURl8LpBI"
   },
   "outputs": [],
   "source": [
    "cd Mask_RCNN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFoMnKwnLunB"
   },
   "outputs": [],
   "source": [
    "!pip install . --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c37uXb1bLvIo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DP0ukRa8NEEa"
   },
   "source": [
    "Now, we download the necessary files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rehtlr-5Lxb5"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/0j983oudb5i6uwc/mask_rcnn_coco.h5?dl=1 -O mask_rcnn_coco.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Okn6wHP7Se4W"
   },
   "source": [
    "We download the dataset. If you are working with Google Colab, you have several options to download the dataset in this notebook, see the available options in the [LabelDetection documentation](https://github.com/ancasag/LabelDetection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgaGXapbShLB"
   },
   "outputs": [],
   "source": [
    "\n",
    "!unzip dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ym8clegBPQ-U"
   },
   "source": [
    "We load the necessary code and start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWwG_WFMabCv"
   },
   "outputs": [],
   "source": [
    "listClasses = ['apple','banana','orange']\n",
    "numImg = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FETPwOYXNKGR"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    " \n",
    "# class that defines and loads the dataset\n",
    "class NewDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir):\n",
    "\t\t# define one class\n",
    "\t\tfor i,cl in enumerate(listClasses):\n",
    "\t\t  self.add_class(\"dataset\", i+1, cl)\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    " \n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor objeto in root.findall('.//object'):\n",
    "\t\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\t\tcoors = [xmin, ymin, xmax, ymax, objeto.find('name').text]\n",
    "\t\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    " \n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index(box[4]))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    " \n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    " \n",
    "# define a configuration for the model\n",
    "class NewConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"model_cfg\"\n",
    "\tBACKBONE = \"resnet50\"\n",
    "\tIMAGE_RESIZE_MODE = \"square\"\n",
    "\tIMAGE_MIN_DIM = 512\n",
    "\tIMAGE_MAX_DIM = 512\n",
    "\t# number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = len(listClasses) + 1\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 4\n",
    "\t# number of training steps per epoch\n",
    "\tSTEPS_PER_EPOCH = numImg // (GPU_COUNT * IMAGES_PER_GPU)\n",
    " \n",
    "# prepare train set\n",
    "train_set = NewDataset()\n",
    "train_set.load_dataset('dataset/train')\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# prepare config\n",
    "config = NewConfig()\n",
    "config.display()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "# load weights (mscoco) and exclude the output layers\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "# train weights (output layers or 'heads')\n",
    "model.train(train_set, train_set, learning_rate=config.LEARNING_RATE, epochs=2, layers='heads')\n",
    "# unfreeze the body of the network and train *all* layers\n",
    "model.train(train_set, train_set, epochs=5,layers=\"all\", learning_rate=config.LEARNING_RATE / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GDUEl-21Or7"
   },
   "source": [
    "Evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Nc8zce_fpNq"
   },
   "outputs": [],
   "source": [
    "numTest = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvkxbN8u1PtZ"
   },
   "outputs": [],
   "source": [
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from numpy import expand_dims\n",
    "from mrcnn.utils import compute_ap\n",
    "from numpy import mean\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"model_cfg\"\n",
    "\tBACKBONE = \"resnet50\"\n",
    "\tIMAGE_RESIZE_MODE = \"square\"\n",
    "\tIMAGE_MIN_DIM = 512\n",
    "\tIMAGE_MAX_DIM = 512\n",
    "\t# number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = len(listClasses) + 1\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "\tBATCH_SIZE = numTest\n",
    "  \n",
    "\n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "\tAPs = list()\n",
    "\tfor image_id in dataset.image_ids:\n",
    "\t\t# load image, bounding boxes and masks for the image id\n",
    "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "\t\t# convert pixel values (e.g. center)\n",
    "\t\tscaled_image = mold_image(image, cfg)\n",
    "\t\t# convert image into one sample\n",
    "\t\tsample = expand_dims(scaled_image, 0)\n",
    "\t\t# make prediction\n",
    "\t\tyhat = model.detect(sample, verbose=0)\n",
    "\t\t# extract results for first sample\n",
    "\t\tr = yhat[0]\n",
    "\t\t# calculate statistics, including AP\n",
    "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\t\t# store\n",
    "\t\tAPs.append(AP)\n",
    "\t# calculate the mean AP across all images\n",
    "\tmAP = mean(APs)\n",
    "\treturn mAP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvYRZ-TW4KjR"
   },
   "outputs": [],
   "source": [
    "cfg = PredictionConfig()\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "import glob\n",
    "modelFile = glob.glob('model_cfg**/*_0005.h5')[0]\n",
    "model.load_weights(modelFile, by_name=True)\n",
    "test_set = NewDataset()\n",
    "test_set.load_dataset('dataset/test')\n",
    "test_set.prepare()\n",
    "test_mAP = evaluate_model(test_set, model, cfg)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMRa2ZhWQKXu"
   },
   "source": [
    "At the end you will have a new folder called model_cfg where you can find the weights of the model. Those weights can be included in the application to be employed with new images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmVhFYqA2Ffg"
   },
   "source": [
    "-----------------\n",
    "\n",
    "\n",
    "## Data distillation\n",
    "\n",
    "After training a model with the annotated images, it is possible to apply a data distillation procedure to create a model using the unlabelled images. You can only apply this techique if there were unlabelled images in your dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iso7sJ4_2Hbw"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ancasag/ensembleObjectDetection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKIvilkd2JrA"
   },
   "outputs": [],
   "source": [
    "cd ensembleObjectDetection/TestTimeAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WNYL1gxx2M2e"
   },
   "outputs": [],
   "source": [
    "!pip install clodsa\n",
    "!pip install gluoncv\n",
    "!pip install mxnet\n",
    "!pip install keras_retinanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLqa_TBZ2Oqp"
   },
   "outputs": [],
   "source": [
    "import testTimeAugmentation\n",
    "import function\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import ensembleOptions\n",
    "from mainTTA import tta\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fz1QnuoQ2Pof"
   },
   "outputs": [],
   "source": [
    "pathImg = '/content/dataset/unlabelled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNIPYIjt2Qwc"
   },
   "outputs": [],
   "source": [
    "myTechniques = [ \"histo\",\"hflip\",\"none\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idC-i7Ti2RmL"
   },
   "outputs": [],
   "source": [
    "option = \"consensus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yR2DEoqZ2Sjw"
   },
   "outputs": [],
   "source": [
    "modelFile = glob.glob('/content/model_cfg**/*_0005.h5')[0]\n",
    "maskRcnn = testTimeAugmentation.MaskRCNNPred(modelFile, '/content/dataset/classes.names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfr9g9fEmtOr"
   },
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0W-UjuX3Uxz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZXED5ZF3W-6"
   },
   "outputs": [],
   "source": [
    "cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "by1D_QrF3b1T"
   },
   "outputs": [],
   "source": [
    "!mv /content/dataset/unlabelled/*.jpg /content/dataset/train/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ti3S9ZK-3fKl"
   },
   "outputs": [],
   "source": [
    "!mv /content/dataset/unlabelled/*.xml /content/dataset/train/annots/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEmk7ZwL_R5R"
   },
   "source": [
    "Restart environment to free memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8UD_QKrS_Udt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UjWQUnSdeq5"
   },
   "outputs": [],
   "source": [
    "listClasses = ['apple','banana','orange']\n",
    "numImg = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMIigKVf6bOD"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "import glob\n",
    " \n",
    "# class that defines and loads the dataset\n",
    "class NewDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir):\n",
    "\t\t# define one class\n",
    "\t\tfor i,cl in enumerate(listClasses):\n",
    "\t\t  self.add_class(\"dataset\", i+1, cl)\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    " \n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor objeto in root.findall('.//object'):\n",
    "\t\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\t\tcoors = [xmin, ymin, xmax, ymax, objeto.find('name').text]\n",
    "\t\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    " \n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index(box[4]))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    " \n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    " \n",
    "# define a configuration for the model\n",
    "class NewConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"model_cfg\"\n",
    "\tBACKBONE = \"resnet50\"\n",
    "\tIMAGE_RESIZE_MODE = \"square\"\n",
    "\tIMAGE_MIN_DIM = 512\n",
    "\tIMAGE_MAX_DIM = 512\n",
    "\t# number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = 3 + 1\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 4\n",
    "\t# number of training steps per epoch\n",
    "\tSTEPS_PER_EPOCH = numImg // (GPU_COUNT * IMAGES_PER_GPU)\n",
    " \n",
    "# prepare train set\n",
    "train_set = NewDataset()\n",
    "train_set.load_dataset('dataset/train')\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# prepare config\n",
    "config = NewConfig()\n",
    "config.display()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "# load weights (mscoco) and exclude the output layers\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "model.train(train_set, train_set, learning_rate=config.LEARNING_RATE, epochs=2, layers='heads')\n",
    "# unfreeze the body of the network and train *all* layers\n",
    "model.train(train_set, train_set, epochs=7,layers=\"all\", learning_rate=config.LEARNING_RATE / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erDigJHg_Kk3"
   },
   "outputs": [],
   "source": [
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from numpy import expand_dims\n",
    "from mrcnn.utils import compute_ap\n",
    "from numpy import mean\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"model_cfg\"\n",
    "\tBACKBONE = \"resnet50\"\n",
    "\tIMAGE_RESIZE_MODE = \"square\"\n",
    "\tIMAGE_MIN_DIM = 512\n",
    "\tIMAGE_MAX_DIM = 512\n",
    "\t# number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = len(listClasses) + 1\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "\tBATCH_SIZE = numTest \n",
    "  \n",
    "\n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "\tAPs = list()\n",
    "\tfor image_id in dataset.image_ids:\n",
    "\t\t# load image, bounding boxes and masks for the image id\n",
    "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "\t\t# convert pixel values (e.g. center)\n",
    "\t\tscaled_image = mold_image(image, cfg)\n",
    "\t\t# convert image into one sample\n",
    "\t\tsample = expand_dims(scaled_image, 0)\n",
    "\t\t# make prediction\n",
    "\t\tyhat = model.detect(sample, verbose=0)\n",
    "\t\t# extract results for first sample\n",
    "\t\tr = yhat[0]\n",
    "\t\t# calculate statistics, including AP\n",
    "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\t\t# store\n",
    "\t\tAPs.append(AP)\n",
    "\t# calculate the mean AP across all images\n",
    "\tmAP = mean(APs)\n",
    "\treturn mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vQMnyvm7-KZ"
   },
   "outputs": [],
   "source": [
    "cfg = PredictionConfig()\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "import glob\n",
    "modelFile = glob.glob('model_cfg**/*_0007.h5')[0]\n",
    "model.load_weights(modelFile, by_name=True)\n",
    "test_set = NewDataset()\n",
    "test_set.load_dataset('dataset/test')\n",
    "test_set.prepare()\n",
    "test_mAP = evaluate_model(test_set, model, cfg)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R86up5pWLR3d"
   },
   "source": [
    "-------------------------------\n",
    "\n",
    "# Using the model in LabelDetection\n",
    "\n",
    "If you want to use the trained model with LabelDetection, you must download the following files:\n",
    "- model_cfg**/*_0007.h5\n",
    "- datasets/classes.names"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MaskRCNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
